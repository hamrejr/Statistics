---
title: "Essential Statistics"
author: "John Hamre III"
date: "August 10, 2017"
output: slidy_presentation
---


- Here I present essential statistics that are generated by using R code
- Many of these are critical for planning a clinical trial
- Further, many can be used in analysis of clinical trial data
- Slides are presented mainly as a title of the statistical test, code and results

Student's t-Test
========================================================

```{r}

problem1 <- read.csv("data/prob1data.csv")
t.test(problem1[,"X2011"],problem1[,"X2012"], paired=TRUE)

#Reject the null hypothesis
#The number of crabs has gone down 

```

Student's t-Test continued
========================================================

```{r}
problem2 <- read.csv("data/prob2data.csv")
prob2_matrix <- as.matrix(problem2[1:dim(problem2)[1], 2:dim(problem2)[2]])
t.test(prob2_matrix[c(1,5,14,17,19), 1:4], prob2_matrix[c(1,5,14,17,19),5:8], paired=FALSE, var.equal = TRUE)
# Reject the null hypothesis 

```
F test to compare two variances, no significance
========================================================

```{r, echo=FALSE}

problem3 <- read.csv("data/prob3data.csv")
 
# First we perform f-tests to assess the variances

prob3_matrix <- as.matrix(problem3[1:dim(problem3)[1], 2:dim(problem3)[2]])
var.test(prob3_matrix[c(1), 1:4], prob3_matrix[c(1),5:8])

# No variances are significant below 95% confidence
 
```

Wilcox test
========================================================

```{r}

wilcox.test(prob3_matrix[c(1), 1:4] , prob3_matrix[c(1),5:8])

# This gene is not significanly different than control using wilcox test



```

Paired Wilcox test
========================================================

```{r}

problem5 <- read.csv("data/prob5data.csv")
wilcox.test(problem5[,"August"],problem5[,"November"], paired=TRUE)
# According to a paired Wilcox, there is 95% confidence that we reject Null

```

Chi-squared distribution
========================================================

```{r}
O = c(57,330,2132,4584,4604,2119,659,251)
E = c(77.9,547.1,2126.7,4283.3,4478.5,2431.1,684.1,107.2)
x2 = sum((O-E)^2/E) 
1-pchisq(x2,5)  

#Extreme statistical significance
#A small P value, as we have here, is evidence that the data are not sampled from the distribution you expected.


```

Least squares
========================================================

```{r, echo=FALSE}
 
problem7 <- read.csv("data/prob7data.csv")
x <- problem7[,1]
y <- problem7[,2]
leastSquares = lm(y ~ x)
summary(leastSquares)

#From the p-values, the conclusion is to reject both null hypotheses that H0 : Bi = 0

```


QQ plot
========================================================

```{r, echo=FALSE}
 
BW = c(135, 120,100,105,130,125,125,105,120,90,120,95,120,150,160,125)
A = c(3,4,3,2,4,5,2,3,5,4,2,3,3,4,3,3)
SBP = c(89,90,83,77,92,98,82,85,96,95,80,79,86,97,92,88)

FIT = fitted (leastSquares) 
RES = resid( leastSquares)
qqplot(FIT,RES, lwd=6, lty=2, col="blue",xlab="Residuals",ylab="Fitted", main="QQ plot Residuals versus Fitted")
qqline(FIT,RES, lwd=3, lty=2, col="red")
 #  possibly the top right data point at ~(98,6.5) could be an outlier
 #It is possible that the residuals could be normaly distributed
```


Least squares plot
========================================================

```{r, echo=FALSE}
 x <- (A + BW)
 y <- SBP
 plot(x,y, pch=19,cex.lab=1.5,col="blue",xlab="(Age(days) + Birth weight(oz))",ylab="Systolic Blood Pressure (mm HG)", main="SBP as a function of Age and Birthweight")
 leastSquares1 = lm(y ~ x)
 abline(leastSquares1$coef, lwd=3, lty=2, col="red")
 


```

knn prediction
========================================================


```{r}
library(class)
library(ISLR)
library(caret)
library(e1071)
knn.pred <- knn(Khan$xtrain,Khan$xtest,Khan$ytrain,k=1)
knn.pred
table(knn.pred, Khan$ytest)

```

Density, distribution function
========================================================


```{r}

sigma = 40
n = 200
mu0 = 190
z=sqrt(n)*(181.52-mu0)/sigma
z
2 * (1-pnorm(abs(z)))
# the Null is rejected
```


Probability of success in a Bernoulli experiment
========================================================


```{r}

binom.test(400, 10000, p = 0.02, alternative = c("greater"),  conf.level = 0.95)
```


Fisher's exact test
========================================================


```{r}
data <- matrix(c(2,5,23,30),2,byrow=TRUE)
tab <- t(matrix(data, nrow=2,ncol=2))
fisher.test(tab)
```
